{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1b3e49-d555-42a5-88bd-7ab75ceb440a",
   "metadata": {},
   "source": [
    "# This is the Group 9 Project Report ipynb File!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca0b343-5b3b-447d-94b8-3a98b492a110",
   "metadata": {},
   "source": [
    "Here is the link to the data set we will be using is the Online News Popularity Dataset from the UCI\n",
    "Machine Learning Respiratory. Subsequent sources can be found in the link on the UCI web page.\n",
    "(Link: https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24841f-280c-4d99-9865-c652d17c8dc2",
   "metadata": {},
   "source": [
    "## Introduction: \n",
    "\n",
    "It is the responsibility of journalists and editors to understand which features of articles may grab the\n",
    "reader’s attention in order to allocate resources effectively, improve the reading experience and increase\n",
    "the sale. There are multiple factors influencing the popularity of the articles which may include \n",
    "contemporaneity, writing quality, and other latent elements (Keneshloo, 2016).To investigate the \n",
    "properties of articles that gain articles, we are interested in determining the features that influence \n",
    "the popularity of an article. The question we are trying to answer is “how many shares will an article \n",
    "have with specific features (i.e., a particular word count, number of images, etc.) generate?” We aim to \n",
    "predict if the number of shares in Social Network, and the popularity, is influenced by these predictors \n",
    "and determine which features are standard in the articles with a higher share-rate. \n",
    "\n",
    "The data set we chose for our project summarizes heterogeneous features of articles published by a digital\n",
    "media platform named “Mashable” over two years. Mashable is a multi-platform media and entertainment \n",
    "company that focuses on publishing news of entertainment, tech, culture and science (Mashable, 2022).\n",
    "In this dataset, there are 61 attributes in total, of which 58 of them are predictive attributes, 2\n",
    "are non-predictive, and 1 is the target field. To have a precise and accurate prediction of what factors \n",
    "can affect the shares (based on the content of an article), we have filtered our columns down, as they \n",
    "are most relevant to our prediction. The features that we are interested in are the 8 listed below:\n",
    "\n",
    "- n_tokens_title: Number of words in the title\n",
    "- n_tokens_content: Number of words in the content\n",
    "- n_unique_tokens: Rate of unique words in the content\n",
    "- num_hrefs: Number of links\n",
    "- num_imgs: Number of images\n",
    "- num_videos: Number of videos\n",
    "- average_token_length: Average length of the words in the content\n",
    "- shares: Number of shares (target)\n",
    "\n",
    "With this filtered data, we anticipate to see a correlation between these features and the number of \n",
    "shares. For the method of data analysis, we plan to use k-nn regression because the value we are \n",
    "predicting (\"shares\") is quantitative. With continuous data, regression is an ideal method which allows\n",
    "a precise prediction in regards to quantity. Further, we plan to visually represent the data on graphs(scatter plot, bar graph, and line graph) for an easier comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f10e20-4555-4efc-b739-d69a1ef1ff78",
   "metadata": {},
   "source": [
    "## Summary of what we Found: \n",
    "\n",
    "Broadly speaking, upon analysis of our knn regression model (and its predictions against the test dataset), no clear correlations were observed between any of the selected predictors and the number of shares of each plotted article. Our model did not predict any positive or negative trends for increasing values of each of the selected predictors, nor did the test values it was predicted against demonstrate such trends. \n",
    "\n",
    "The 7 aforementioned selected predictors central to the project included the number of images, number of words in content, number of words in the title, number of links, average word length, and positivity and negativity rates. None of these were found to demonstrate a strong correlation that indicates a direct impact on the number of shares. What was observed, however, was a certain range that the majority of articles with a high number of overall shares fit within.\n",
    "\n",
    "A higher number of images contained in an article was found to not necessarily lead to a higher number of article shares. In fact, many articles with no images still had a large number of shares (3000+). \n",
    "\n",
    "No significant correlation is observed between the word count of an article’s content and the number of shares that those articles generate, but generally speaking, there are more articles with 1500 or fewer total words that generate 3000+ shares.\n",
    "\n",
    "No correlation is observed between the number of links and shares. However, there is a greater density of articles with 3000+ shares that have 10 or fewer links embedded within.\n",
    "There appears to be no correlation between the number of images in an article and the number of shares that the article generates - there is a greater density of higher numbers of total shares for articles with 2 or fewer images, however.\n",
    "Moreover, there is no correlation between the average word length in an article and the number of article shares, but broadly speaking, there is a greater density of articles with 3000+ shares amongst the range of articles with 4.5-5.0 average word length.\n",
    "Finally, the relationships between positivity and negativity rates and the number of article shares do not demonstrate a clear trend. However, it is observed that most articles have positive words at a rate of more than 0.5, and negative words at a rate of less than 0.5. \n",
    "\n",
    "## What we expected to Find:\n",
    "\n",
    "It is without a doubt that this is not in agreement with what we initially expected. Upon perusal of the various predictors present in the selected dataset, initial conclusions of possible relationships between predictors (specified elements of articles) and the number of article shares were hypothesized. Specifically, there was an initial expectation that articles of higher popularity (ie, those with a greater number of shares), would have a higher number of images and videos, but not overly excessive in terms of article word count, the number of words in the title, and average word length  (a relatively middle ground in each of these areas was expected to maximize shares). The vast majority of these predictors (and their expected impact on article popularity, which could be better understood using the number of shares as a proxy) were considered under the lens of viewer engagement; more images and videos, and a manageable overall article word count would be expected to draw viewers in and maintain their attention, leaving them more likely to share a given article with their acquaintances. With regards to positivity and negativity rates, there was an initial expectation that articles with higher rates of each would correspond to higher and lower total shares respectively - this being connected to the feelings induced and impact experienced by those reading articles with words associated with positive versus negative emotions. \n",
    "\n",
    "## Impacts of what we found\n",
    "\n",
    "These findings are significant in that one can pinpoint instances where specific values associated with any of the selected predictors are more likely to result in an article gaining a significant number of shares, thereby allowing for an article to be shaped in a way that optimizes its popularity. Specifically, while the predictors are not associated with any sort of positive trend in the number of shares, there may be instances in which there is a peak in the middle of the data - a “middle-ground” so to speak. In this way, we may identify ranges of average word length, the number of images and links, as well as other predictors, which more often than not generate high levels of the number of shares, and use this to educate the way in which articles are written. For instance, articles with fewer than 1500 words and a title that is 5-15 words in length are predicted to have a very high number of overall shares. \n",
    "\n",
    "## Future questions\n",
    "\n",
    "In order to provide useful recommendations in the future to maximize the shares, we will have further research on other possible and potential factors that might impact the shares. Given the predictors we examined did not amount to the identification of any clear relationships, there are two follow-up considerations we intend to examine. \n",
    "\n",
    "The first is with regards to questions that would help us ascertain whether there exist other article elements that have a clear correlation with the number of article shares. Is publishing time on weekends likely to lead to more shares of articles than the weekdays? Are websites with more page views leading to more shares of articles? What kind of subjects leads to more shares of articles? Does different weather affect the shares of articles? Will different regions or countries affect the shares of articles? Will different age groups affect the shares of articles?\n",
    "\n",
    "The second future consideration is with regard to the data we use to make predictions. It is entirely likely that our dataset, if expanded, could provide a better representation of possible relationships between article elements and the number of shares, in a manner that is not as susceptible to outliers in the dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864323b5-178c-4458-8091-609f61147c38",
   "metadata": {},
   "source": [
    "The following cell loads the packages that will be used for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd451b-d57e-4f9d-875b-753a02166874",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(testthat)\n",
    "library(digest)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(GGally)\n",
    "library(ISLR)\n",
    "library(infer)\n",
    "library(cowplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1bda3-1e42-4d6b-abe3-cceae38c3dae",
   "metadata": {},
   "source": [
    "This cell will import our data from a link. The link is to a public GitHub with the data, as the direct website link gives us a .zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d4a43-4d56-470e-b914-86275db185ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "url <- \"https://raw.githubusercontent.com/EPICxFLIPPER/data/main/OnlineNewsPopularity.csv\"\n",
    "popularity <- read_csv(url) \n",
    "\n",
    "head(popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f13654-0e9f-4a1c-ae4d-181123f76a65",
   "metadata": {},
   "source": [
    "**Table 1:** Shows the data set loaded in without any changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b253276-34e6-4858-a1fd-8c7c1fb2dd1e",
   "metadata": {},
   "source": [
    "The next cell wrangles our data. This data was already quite tidy, only a few null values had to be removed. We also selected only our predictors and the shares coloum (bing predicted). We selected these predictors as they would be easily manipulated by a humans writing an article. Through our exploritory analysis, there were quite a few outlier points, the have been removed. Futhermore, values of 0 that simply don't make sense were removed, such as a value of 0 in word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b1f86-696d-4de1-b067-9c6ddaad1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9)\n",
    "#Wrangling\n",
    "popularity_tidy <- popularity |> \n",
    "#removing columns that are specifically not litsted as predictors as well as columns that self reference articles.\n",
    "select(-url, -timedelta) |>\n",
    "# select(n_tokens_title:average_token_length, shares) |>\n",
    "select(n_tokens_title:shares, -num_videos, -n_non_stop_words , -n_non_stop_unique_tokens,\n",
    "      -data_channel_is_lifestyle:-is_weekend,-LDA_00:-LDA_04, - num_self_hrefs, -num_keywords:-global_rate_negative_words,\n",
    "      -avg_positive_polarity: -abs_title_sentiment_polarity, -n_unique_tokens) |>\n",
    "filter(shares < 5000)|>\n",
    "arrange(desc(shares)) |>\n",
    "drop_na(n_tokens_content:shares) |>\n",
    "#Removing valeus where 0 doesnt make sense\n",
    "filter(n_tokens_title >0) |>\n",
    "filter(n_tokens_content>0) |>\n",
    "filter(average_token_length>0) |>\n",
    "filter(shares>0)\n",
    "\n",
    "\n",
    "\n",
    "head(popularity_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de34586-b05b-4a42-87d9-61dae31f9b08",
   "metadata": {},
   "source": [
    "**Table 2:** Shows the wrangeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b451c6-65e7-4035-b8bc-5f8099c3738c",
   "metadata": {},
   "source": [
    "In the following line we will take a sample from our data to explore. This is because with such a large data set the R kerenl would crash. A random sample of sufficient size should be representative of the population enough to allow for continued exploration of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deeaf53-a4d6-442f-9f9d-139319b3f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9)\n",
    "popularity_sample <- rep_sample_n(popularity_tidy, 5000,replace = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05485f-0a6e-4dd3-b8c9-385ecef30f8c",
   "metadata": {},
   "source": [
    "In the next cell we split the data into training and testing data. 80% in the training set, stratzised by shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a2f78-c828-4b16-b762-a21c5a6cf362",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9)\n",
    "#Splitting the data into training and testing data\n",
    "#Strata = the day the article was published\n",
    "popularity_split<- initial_split(popularity_sample, prop = .80, strata = shares)\n",
    "popularity_train<- training(popularity_split)\n",
    "popularity_test <- testing(popularity_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95d81d-0c24-483d-bd59-9d900605c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9)\n",
    "initial_table <- popularity_train |>\n",
    "map_df(mean,na.rm =TRUE)\n",
    "initial_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6902a-f133-4db6-a95d-93393d16ada7",
   "metadata": {},
   "source": [
    "**Tabel 3:** This table shows the averages of each of the predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cb8ec-acc2-4e5d-a743-b75129722ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9)\n",
    "#Below are the distributions of the 3 most varable categoreis in our data set. Though some of the categories are less variable, we belive \n",
    "#they will still be good predictors of shares.\n",
    "\n",
    "options(repr.plot.width = 20, repr.plot.height =7)\n",
    "\n",
    "shares_plot <- popularity_train |> \n",
    "ggplot(aes(x = shares)) + geom_histogram(binwidth = 100)+xlim(0,5000) +labs(x = \"Shares\" , y = \"Frequency\") +\n",
    "ggtitle(\"Distribuion of Shares (Fig 1.0)\") + theme(text = element_text(size = 20))\n",
    "\n",
    "\n",
    "shares_vs_imgs_plot <- popularity_train |>\n",
    "ggplot(aes(x = num_imgs , y = shares)) + geom_point(alpha = .3) + xlab(\"Images\") + ylab(\"Shares\") +\n",
    "ggtitle(\"Shares vs Images (Fig 1.4)\") +\n",
    "theme(text = element_text(size = 20))\n",
    "\n",
    "shares_vs_word_count_plot <- popularity_train |>\n",
    "ggplot(aes(x = n_tokens_content , y = shares)) + geom_point(alpha = .3) + xlab(\"Word Count\") + ylab(\"Shares\") +\n",
    "ggtitle(\"Shares vs Word Count (Fig 1.2)\") +\n",
    "theme(text = element_text(size = 20))\n",
    "\n",
    "shares_vs_token_length_plot <- popularity_train |>\n",
    "ggplot(aes(x = average_token_length , y = shares)) + geom_point(alpha = .3) + xlab(\"Average Word Length\") + ylab(\"Shares\") +\n",
    "ggtitle(\"Shares vs Avg Word Length (Fig 1.5)\") +\n",
    "theme(text = element_text(size = 20))\n",
    "\n",
    "shares_vs_title_plot <- popularity_train |>\n",
    "ggplot(aes(x = n_tokens_title , y = shares)) + geom_point(alpha = .3) + xlab(\"Words in Title\") + ylab(\"Shares\") +\n",
    "ggtitle(\"Shares vs Words in Title (Fig 1.1)\") +\n",
    "theme(text = element_text(size = 20))\n",
    "\n",
    "shares_vs_links_plot <- popularity_train |>\n",
    "ggplot(aes(x = num_hrefs , y = shares)) + geom_point(alpha = .3) + xlab(\"Links\") + ylab(\"Shares\") +\n",
    "ggtitle(\"Shares vs Links (Fig 1.3)\") +\n",
    "theme(text = element_text(size = 20))\n",
    "\n",
    "shares_vs_positive_plot <- popularity_train |>\n",
    "ggplot(aes(x = rate_positive_words , y = shares)) + geom_point(alpha = .3) + xlab(\"Positive words rate\") + ylab(\"Shares\") +\n",
    "ggtitle(\"Shares vs Positivity (Fig 1.6)\") +\n",
    "theme(text = element_text(size = 20))\n",
    "\n",
    "shares_vs_negative_plot <- popularity_train |>\n",
    "ggplot(aes(x = rate_negative_words , y = shares)) + geom_point(alpha = .3) + xlab(\"Negative words rate\") + ylab(\"Shares\") +\n",
    "ggtitle(\"Shares vs Negativity (Fig 1.7)\") +\n",
    "theme(text = element_text(size = 20))\n",
    "\n",
    "plots <- plot_grid(\n",
    "    shares_vs_title_plot,\n",
    "    shares_vs_word_count_plot,\n",
    "    shares_vs_links_plot,\n",
    "    shares_vs_imgs_plot,\n",
    "    shares_vs_token_length_plot,\n",
    "    shares_vs_positive_plot,\n",
    "    shares_vs_negative_plot,\n",
    "ncol = 3) \n",
    "shares_plot\n",
    "plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410e5e5-76d2-49c6-89e0-bb3149122732",
   "metadata": {},
   "source": [
    "- **Fig1.0:** Distribution of Shares\n",
    "- **Fig1.1:** Shares vs Words in Title\n",
    "- **Fig1.2:** Shares vs Word Count\n",
    "- **Fig1.3:** Shares vs Links\n",
    "- **Fig1.4:** Shares vs Images\n",
    "- **Fig1.5:** Shares vs Word Length\n",
    "- **Fig1.6:** Shares vs Positivity Rate\n",
    "- **Fig1.7:** Shares vs Negativity Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33a497-b0ed-43a8-814f-9260fd5d0d2e",
   "metadata": {},
   "source": [
    "The following cell is for cross validation. From our exploritory analysis we can see that none of the relationships in figures 1.1-1.7 are particullarly linear. Because of this we will be using a KNN regression model. We need to find the best number of neighobrs to predict off of. We will be using a 5 fold cross validation shown below. Note that we are testing neighbors 40-80 as though this process we see the most efficient number of neighbors in this range. Reducing the range saves running time for the viewer of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db4185-78ea-4a10-8efa-4e7ee6f41964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will be loacting the best neighbors to use\n",
    "set.seed(9)\n",
    "popularity_spec <- nearest_neighbor(weight_func = \"rectangular\" , neighbors = tune()) |> \n",
    "set_engine(\"kknn\") |> \n",
    "set_mode(\"regression\")\n",
    "\n",
    "popularity_recipe <- recipe(shares~., data = popularity_train) |> \n",
    "step_scale(all_predictors()) |> \n",
    "step_center(all_predictors())\n",
    "\n",
    "gridvals <- tibble(neighbors = seq(from = 40, to = 80, by = 1))\n",
    "popularity_vfold <- vfold_cv(data = popularity_train, v = 5, strata = shares)\n",
    "\n",
    "popularity_fit <- workflow() |>\n",
    "add_recipe(popularity_recipe) |>\n",
    "add_model(popularity_spec) |>\n",
    "tune_grid(resamples = popularity_vfold, grid = gridvals) |>\n",
    "collect_metrics() |>\n",
    "filter(.metric == \"rmse\") |>\n",
    "arrange(mean) |>\n",
    "select(neighbors) |>\n",
    "slice(1) |>\n",
    "pull()\n",
    "\n",
    "\n",
    "\n",
    "popularity_fit\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b0de6d-4843-44b0-947d-5e33fb68a5bb",
   "metadata": {},
   "source": [
    "Next We will train our data with the number of predictors found above as well as compare our predictions to the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81e469-6bdd-4514-bbe5-fb56d4540c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9)\n",
    "popularity_spec_2 <- nearest_neighbor(weight_func = \"rectangular\", neighbors = popularity_fit) |> \n",
    "set_engine(\"kknn\") |> \n",
    "set_mode(\"regression\")\n",
    "\n",
    "popularity_fit_2 <- workflow() |> \n",
    "add_recipe(popularity_recipe) |>\n",
    "add_model(popularity_spec_2) |>\n",
    "fit(data = popularity_train)\n",
    "\n",
    "popularity_predictions <- predict(popularity_fit_2, popularity_test) |> \n",
    "bind_cols(popularity_test)\n",
    "\n",
    "head(popularity_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d98aef-5f7d-4b19-8b27-245cc0575547",
   "metadata": {},
   "source": [
    "**Tabel 4:** Shows the data with the prediction column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c79b71-feb5-4748-93e3-42dc9725df2b",
   "metadata": {},
   "source": [
    "Below we will explore a few of our predictors vs share plots again this time with how the shares were predicted overlayed onto the graphs. The graphs corrospond to the following figure labels:\n",
    "\n",
    "- Fig2.0: Shares vs Words in Title\n",
    "- Fig2.1: Shares vs Word Count\n",
    "- Fig2.2: Shares vs Links\n",
    "- Fig2.3: Shares vs Images\n",
    "- Fig2.4: Shares vs Word Length\n",
    "- Fig2.5: Shares vs Positivity Rate\n",
    "- Fig2.6: Shares vs Negativity Rate\n",
    "\n",
    "The plots have been intentionally left fairly large to better see the predcitons, which are represented by the blue line on each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acbc05c-0307-4be0-850a-789328434214",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9)\n",
    "options(repr.plot.width = 12 , repr.plot.height =7)\n",
    "plot_1 <- popularity_train |> \n",
    "ggplot(aes(x = n_tokens_content , y = shares )) + geom_point(alpha = .5) +\n",
    "geom_line(data = popularity_predictions , aes(x = n_tokens_content , y = .pred), color = \"blue\") +\n",
    "labs(x = \"Word Count in Content\" , y = \"Shares\", color = \"Predictions\")+\n",
    "ggtitle(\"Shares vs Word Count (W/Predictions)Fig2.1\") + theme(text = element_text(size = 20)) + xlim(0,3000)\n",
    "\n",
    "\n",
    "plot_2 <- popularity_train |> \n",
    "ggplot(aes(x = n_tokens_title , y = shares )) + geom_point(alpha = .5) +\n",
    "geom_line(data = popularity_predictions , aes(x = n_tokens_title , y = .pred), color = \"blue\") + xlim(0,20) +\n",
    "theme(text = element_text(size = 20)) + labs(x = \"Words in Title\" , y = \"Shares\", color = \"Predictions\") +\n",
    "ggtitle(\"Shares vs Words in Title (W/Predictions) Fig2.0\")\n",
    "\n",
    "\n",
    "plot_3 <- popularity_train |> \n",
    "ggplot(aes(x = rate_positive_words , y = shares )) + geom_point(alpha = .5) +\n",
    "geom_line(data = popularity_predictions , aes(x = rate_positive_words , y = .pred), color = \"blue\") + xlim(0,1) +\n",
    "theme(text = element_text(size = 20)) + labs(x = \"Positivity Rate\" , y = \"Shares\" , color = \"Predictions\")+\n",
    "ggtitle(\"Shares vs Positivity (W/Predictions)Fig2.5\")\n",
    "\n",
    "\n",
    "plot_4 <- popularity_train |> \n",
    "ggplot(aes(x = average_token_length , y = shares )) + geom_point(alpha = .5) +\n",
    "geom_line(data = popularity_predictions , aes(x = average_token_length , y = .pred), color = \"blue\") + xlim(4,5.5) +\n",
    "theme(text = element_text(size = 20))+labs(x = \"Average Word Length\" , y = \"Shares\" , color = \"Predictions\")+\n",
    "ggtitle(\"Shares vs Word Length (W/Predictions)Fig2.4\")\n",
    "\n",
    "\n",
    "plot_5 <- popularity_train |> \n",
    "ggplot(aes(x = num_imgs , y = shares )) + geom_point(alpha = .5) +\n",
    "geom_line(data = popularity_predictions , aes(x = num_imgs , y = .pred), color = \"blue\") + xlim(0,20) +\n",
    "theme(text = element_text(size = 20))+labs(x = \"Images\" , y = \"Shares\" , color = \"Predictions\")+\n",
    "ggtitle(\"Shares vs Images (W/Predictions)Fig2.3\")\n",
    "\n",
    "\n",
    "plot_6 <- popularity_train |> \n",
    "ggplot(aes(x = num_hrefs , y = shares )) + geom_point(alpha = .5) +\n",
    "geom_line(data = popularity_predictions , aes(x = num_hrefs , y = .pred), color = \"blue\") + xlim(0,20) +\n",
    "theme(text = element_text(size = 20))+labs(x = \"Links\" , y = \"Shares\" , color = \"Predictions\")+\n",
    "ggtitle(\"Shares vs Links (W/Predictions)Fig2.2\")\n",
    "\n",
    "\n",
    "plot_7 <- popularity_train |> \n",
    "ggplot(aes(x = rate_negative_words , y = shares )) + geom_point(alpha = .5) +\n",
    "geom_line(data = popularity_predictions , aes(x = rate_negative_words , y = .pred), color = \"blue\") + xlim(0,1) +\n",
    "theme(text = element_text(size = 20)) + labs(x = \"Negativity Rate\" , y = \"Shares\" , color = \"Predictions\")+\n",
    "ggtitle(\"Shares vs Negativity (W/Predictions)Fig2.6\")\n",
    "\n",
    "plot_2\n",
    "plot_1\n",
    "plot_6\n",
    "plot_5\n",
    "plot_4\n",
    "plot_3\n",
    "plot_7\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e0496-bb25-4bf0-8ff6-2c67b75659e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
